---
title: Build a management solution in OMS | Microsoft Docs
description: Management solutions extend the functionality of Operations Management Suite (OMS) by providing packaged management scenarios that customers can add to their OMS workspace.  This article provides details on how you can create management solutions to be used in your own environment or made available to your customers.
services: operations-management-suite
documentationcenter: ''
author: bwren
manager: carmonm
editor: tysonn

ms.assetid: 1915e204-ba7e-431b-9718-9eb6b4213ad8
ms.service: operations-management-suite
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: infrastructure-services
ms.date: 03/02/2017
ms.author: bwren

ms.custom: H1Hack27Feb2017

---
# Design and build a management solution in Operations Management Suite (OMS) (Preview)
> [!NOTE]
> This is preliminary documentation for creating management solutions in OMS which are currently in preview. Any schema described below is subject to change.  

Every [management solution in Operations Management Suite (OMS)](operations-management-suite-solutions.md) has unique requirements, and each one can include any set of Azure resources required to perform a particular management function. This article presents a basic process to design and build a management solution that is suitable for the most common requirements.  If you are new to building management solutions then you can use this process as a starting point and then leverage the concepts for more complex solutions as your requirements evolve.


## Solution design

You should start your management solution by building the individual components in your Azure environment.  Once you have the functionality working properly, then you can start packaging them into a [management solution file](operations-management-suite-solutions-solution-file.md).

The most common pattern for a management solution is shown in the following diagram.  The different components in this pattern are discussed in the following section.

![OMS solution overview](media/operations-management-suite-solutions/solution-overview.png)


### Data sources
The first step in designing a solution is determining the data that you require from the Log Analytics repository.  This data may be collected by a [data source](../log-analytics/log-analytics-data-sources.md) or another solution, or your solution may need to provide the process to collect it.

There are a number of ways data sources that can be collected in the Log Analytics repository as described in [Data sources in Log Analytics](../log-analytics/log-analytics-data-sources.md).  This includes events in the Windows Event Log or generated by Syslog in addition to performance counters for both Windows and Linux clients.  You can also gathered for Azure resources by Azure Monitor.  

If you require data that's not accessible through any of the data sources, then you can use the [HTTP Data Collector API](../log-analytics/log-analytics-data-collector-api.md) which allows you to write data to the Log Analytics repository from any client that can call a REST API.  The most common means of custom data collection in a management solution is to create a [runbook in Azure Automation](../automation/automation-runbook-types.md) that collects the required data and uses the Data Collector API to write to the repository.  Runbooks are written in PowerShell and can access other services and applications in Azure as well as other clouds.

### Log searches
[Log searches](../log-analytics/log-analytics-log-searches.md) are used to extract and analyze data in the Log Analytics repository.  They are used by views and alerts in addition to allowing the user to perform ad hoc analysis of data in the repository.  

You should define any queries that you think will be helpful to the user even if they aren't used by any views or alerts.  These will be available to them as Saved Searches in the portal, and you can also include then in a [List of Queries visualization part](../log-analytics/log-analytics-view-designer-parts.md#list-of-queries-part) in your custom view.

### Alerts
Alerts notify the user to important information in the Log Analytics repository.  This could be information such as an error detected in the application or a performance counter crossing a critical threshold.  

In addition to notifying the user of the detected issue, alerts can create responses such as starting a runbook or calling a webhook.  You should 

### Views
Views in Log Analytics are used to visualize data from the Log Analytics repository.  You can [create custom views using  the View Designer](../log-analytics/log-analytics-view-designer.md) which you can later export for inclusion in your solution file.

Each solution will typically contain a single view with a [tile](../log-analytics/log-analytics-view-designer-tiles.md) that is displayed on the user's main dashboard.  The view can contain any number of [visualization parts](../log-analytics/log-analytics-view-designer-parts.md) to provide different visualizations of the collected data to the user.


## Create solution file
Once you've configured and tested the components that will be part of your solution, you can [create your solution file](operations-management-solutions-solution-file.md).  You will implement the solution components in a Resource Manager template that includes a [solution resource]() with relationships to the other resources in the file.  

You can get complete guidance on creating a solution file at []().  This section provides best practices for implementing different kinds of resources.

### Data sources
Data sources can be [configured with a Resource Manager template](../log-analytics/log-analytics-template-workspace-configuration.md), but we do not recommend that you include them in a solution file.  The reason is that configuring data sources is not currently idempotent meaning that your solution could overwrite existing configuration in the user's workspace.  

For example, your solution may require Warning and Error events from the Application event log.  If you specify this as a data source in your solution, you risk removing Information events if the user had this configured in their workspace.  If you included all events, then you may be collecting excessive Information events in the user's workspace.

**Best practices**

- If your solution requires data from one of the standard data sources, then you should define this as a prerequisite.  State in documentation that the customer must configure the data source on their own.  
- Add a [Data Flow Verification](../log-analytics/log-analytics-view-designer-tiles.md) message to any views in your solution to instruct the user on data sources that need to be configured for required data to be collected.


### Runbooks
You can include any runbooks in the solution file so that their created when the solution is installed.  You cannot contain the body of the runbook in the template though, so you should publish the runbook to a public location where 

**Best practices**

- Create an [Automation schedule](../automation/automation-schedules.md) for each runbook in your solution that needs to run on a schedule.
- Contain runbooks in the solution so they're removed when the solution is removed.
- Include the [IngestionAPI module](../log-analytics/log-analytics-data-collector-api.md) in your runbook to simplify writing data to the Log Analytics repository.  Do not contain this module in the solution so that it remains if the solution is removed.  This allows multiple solutions to share the module.


### Views
You include a view in a solution by [exporting it and then adding it to the solution file]().  

**Best practices**

- All solutions should include a single view that is displayed in the user's portal.  The view can contain multiple automation parts to illustrate different sets of data.
- Add a [Data Flow Verification](../log-analytics/log-analytics-view-designer-tiles.md) message to any views in your solution to instruct the user on data sources that need to be configured for required data to be collected.

### Alerts
Alerts identify issues identified in your solution and either notify the user or automatically run an action in response. You should identify different alert conditions and include corresponding alert rules in your solution file.

**Best practices**

- Define the recipients list as a parameter in the solution file so the user can define them when they install the solution.
- Don't contain the alert rules in the solution to allow the user to change their configuration.  They may want to make changes such as modifying the recipient list, changing the threshold of the alert, or disabling the rule. 



## Publish solution






## Other resources
You can get the details and samples of resources that are common to management solutions in the following articles.

* [Views and dashboards](operations-management-suite-solutions-resources-views.md)
* [Automation resources](operations-management-suite-solutions-resources-automation.md)

## Testing a management solution
Prior to deploying your management solution, it is recommended that you test it using [Test-AzureRmResourceGroupDeployment](../azure-resource-manager/resource-group-template-deploy.md#deploy).  This will validate your solution file and help you identify any problems before attempting to deploy it.

## Next steps
* [Add saved searches and alerts](operations-management-suite-solutions-resources-searches-alerts.md) to your management solution.
* [Add views](operations-management-suite-solutions-resources-views.md) to your management solution.
* [Add Automation runbooks and other resources](operations-management-suite-solutions-resources-automation.md) to your management solution.
* Learn the details of [Authoring Azure Resource Manager templates](../azure-resource-manager/resource-group-authoring-templates.md).
* Search [Azure Quickstart Templates](https://azure.microsoft.com/documentation/templates) for samples of different Resource Manager templates.
